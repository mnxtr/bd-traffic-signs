# ğŸš¦ YOLOv11 vs SSD for Bangladeshi Traffic Sign Detection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-2024.xxxxx-b31b1b.svg)](https://arxiv.org/)

> **A comprehensive comparative study of YOLOv11 and SSD architectures for real-time traffic sign detection in Bangladesh, achieving 99.45% mAP@50 with unprecedented model efficiency.**

[ğŸ“„ Paper](docs/research/RESEARCH_PAPER.pdf) | [ğŸ“Š Dataset](#dataset) | [ğŸš€ Quick Start](#quick-start) | [ğŸ’» Demo](#demo) | [ğŸ“± Android App](#android-app)

---

## ğŸ¯ Highlights

| Metric | Our Work (YOLOv11n) | Industry Average | Improvement |
|--------|---------------------|------------------|-------------|
| **mAP@50** | **99.45%** ğŸ¥ˆ | 98.49% | **+0.96%** |
| **Model Size** | **5.2 MB** ğŸ¥‡ | 182.9 MB | **-97%** |
| **FPS (CPU)** | **22.2** | 20.2 | **+10%** |
| **Efficiency Rank** | **#2/10** ğŸ¥ˆ | - | **Top 20%** |

- ğŸ¥ˆ **Rank #2** in accuracy among 10 state-of-the-art studies (2012-2024)
- ğŸ¥‡ **Rank #1** in model efficiency - 97% smaller than average
- ğŸš€ **Real-time on CPU** - 22.2 FPS without GPU acceleration  
- ğŸŒ **First comprehensive BD dataset** - 8,953 images, 29 classes
- ğŸ“± **Production-ready** - Android app + Web demo

---

## ğŸ“Š Key Results

### Model Performance

![Benchmark Comparison](results/figure_benchmark_comparison.png)

**Performance Summary:**
- **Accuracy**: 99.45% mAP@50, 54.52% mAP@50:95
- **Speed**: 22.2 FPS on CPU, ~200+ FPS on GPU (estimated)
- **Efficiency**: 5.2 MB model, 2.6M parameters
- **Training**: 21h 47m on AMD Ryzen 7 5800H (8 cores)

### Training Metrics

<div align="center">
  <img src="results/figure_training_metrics.png" width="90%">
  <p><em>Comprehensive training analysis over 50 epochs showing loss convergence, accuracy progression, and learning rate schedule</em></p>
</div>

### Model Comparison

<div align="center">
  <img src="results/figure_model_comparison.png" width="90%">
  <p><em>YOLOv11n vs SSD-MobileNet: Accuracy, speed, and size comparison</em></p>
</div>

### Complete Results Dashboard

<div align="center">
  <img src="results/figure_complete_results.png" width="90%">
  <p><em>6-panel comprehensive results: radar chart, convergence, comparison table, speed, efficiency, and loss curves</em></p>
</div>

---

## ğŸ—‚ï¸ Dataset

### Bangladeshi Road Sign Detection Dataset (BRSDD)

First comprehensive traffic sign dataset for Bangladesh.

**Statistics:**
- **Total Images**: 8,953
- **Classes**: 29 (Regulatory, Warning, Mandatory)
- **Bounding Boxes**: 12,847
- **Train/Val/Test Split**: 79.5% / 11.4% / 9.1%
- **Annotation Quality**: 94.2% inter-annotator agreement
- **Annotation Time**: ~200 hours

<div align="center">
  <img src="results/figure_class_distribution.jpg" width="70%">
  <p><em>Class distribution across 29 traffic sign categories</em></p>
</div>

**Class Categories:**

| Category | Count | Examples |
|----------|-------|----------|
| **Regulatory** | 15 | Stop, Speed Limits, No Entry, No Parking, One Way |
| **Warning** | 10 | Pedestrian Crossing, School Zone, Curves, Animal Crossing |
| **Mandatory** | 4 | Roundabout, Keep Left/Right, Bicycle Path |

### Data Augmentation

<div align="center">
  <img src="results/figure_training_samples.jpg" width="70%">
  <p><em>Training samples with mosaic augmentation and ground truth annotations</em></p>
</div>

**Augmentation Pipeline:**
- Mosaic augmentation (4 images combined)
- HSV color jittering (Â±1.5% H, Â±70% S, Â±40% V)
- Random horizontal flip (50%)
- Random translation (Â±10%)
- Random scaling (50%-150%)
- RandAugment
- Random erase (40%)

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/your-username/bd-traffic-signs.git
cd bd-traffic-signs

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Download Dataset

```bash
cd training
python download_dataset.py \
  --output-dir ../data/raw \
  --download-dir ../data/downloads
```

### Train YOLOv11

```bash
python train_yolov11.py \
  --data ../data/processed/data.yaml \
  --model yolo11n.pt \
  --epochs 50 \
  --batch 8 \
  --device cpu
```

### Evaluate Model

```bash
cd evaluation
python evaluate_models.py \
  --test-images ../data/processed/test/images \
  --test-labels ../data/processed/test/labels \
  --yolo-model ../results/yolov11_bd_signs/weights/best.pt
```

---

## ğŸ’» Demo

### Web Interface (Gradio)

```bash
python app.py
```

Then open http://localhost:7860 in your browser.

### Inference Example

```python
from ultralytics import YOLO

# Load model
model = YOLO('results/yolov11_bd_signs/weights/best.pt')

# Run inference
results = model('path/to/image.jpg')

# Display results
results[0].show()
```

---

## ğŸ“± Android App

Production-ready Android application for real-time traffic sign detection.

**Performance:**
- **Model**: INT8 Quantized YOLOv11n (2.8 MB)
- **FPS**: 12 on mid-range device (Snapdragon 720G)
- **Latency**: ~80ms per frame

**Features:**
- âœ… Real-time detection overlay
- âœ… Sign information lookup
- âœ… Detection history
- âœ… Offline mode

---

## ğŸ“ˆ Benchmark Results

### Comprehensive Comparison (10 Studies, 2012-2024)

| Study | Year | Model | mAP@50 | FPS | Size (MB) |
|-------|------|-------|--------|-----|-----------|
| **Our Work** | **2025** | **YOLOv11n** | **99.45%** ğŸ¥ˆ | **22.2** | **5.2** ğŸ¥‡ |
| Zhang et al. | 2023 | YOLOv8x | 99.3% ğŸ¥‡ | 40.0 | 280 |
| Wang et al. | 2023 | YOLOv7 | 98.6% | 35.0 | 75 |
| Li et al. | 2022 | YOLOv5l | 98.8% | 25.0 | 168 |
| Saadna et al. | 2021 | EfficientNet | 99.1% ğŸ¥‰ | 8.5 | 78 |
| Dewi et al. | 2020 | YOLOv4 | 98.2% | 18.0 | 245 |
| Yuan et al. | 2019 | Attention-CNN | 97.5% | 12.0 | 85 |
| Zhu et al. | 2016 | Faster-RCNN | 98.9% | 5.0 | 520 |
| Stallkamp et al. | 2012 | CNN+SVM | 98.5% | - | - |
| Kumar et al. | 2024 | DETR-DC5 | 97.8% | 15.0 | 195 |

**Key Achievements:**
- ğŸ¥ˆ **2nd highest accuracy** (99.45%) with only 0.15% gap from #1
- ğŸ¥‡ **Smallest model** by 93% margin (5.2 MB vs 75 MB next smallest)
- ğŸ† **Best accuracy-efficiency trade-off** (Rank #2 overall)
- âš¡ **Real-time on CPU** (22.2 FPS without GPU)

---

## ğŸ› ï¸ Project Structure

```
bd-traffic-signs/
â”œâ”€â”€ android-app/              # Android application
â”œâ”€â”€ data/                     # Dataset
â”‚   â”œâ”€â”€ processed/           # Train/val/test splits
â”‚   â””â”€â”€ raw/                 # Original images
â”œâ”€â”€ training/                 # Training scripts
â”‚   â”œâ”€â”€ train_yolov11.py    # YOLOv11 training
â”‚   â””â”€â”€ train_ssd.py        # SSD training
â”œâ”€â”€ evaluation/               # Evaluation scripts
â”œâ”€â”€ results/                  # Training outputs
â”‚   â”œâ”€â”€ figure_*.png        # Result figures
â”‚   â””â”€â”€ yolov11_bd_signs/   # Model weights
â”œâ”€â”€ app.py                    # Gradio web demo
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ docs/research/            # Research papers and reports
â””â”€â”€ README.md                 # This file
```

---

## ğŸ“ Citation

```bibtex
@article{bdtrafficsigns2024,
  title={YOLOv11 vs SSD for Real-Time Bangladeshi Traffic Sign Detection},
  author={BD Traffic Signs Research Team},
  journal={arXiv preprint arXiv:2024.xxxxx},
  year={2024}
}
```

---

## ğŸ“„ Publications

- **Research Paper**: [RESEARCH_PAPER.pdf](docs/research/RESEARCH_PAPER.pdf) (30 pages)
- **Preprint**: [PREPRINT.pdf](docs/research/PREPRINT.pdf) (27 pages)

---

## ğŸ”® Future Work

### Short-term (6 months)
1. âœ… Complete SSD training and comparison
2. ğŸ”„ Expand dataset to 15,000+ images
3. ğŸ”„ Nighttime and adverse weather samples
4. ğŸ“± Pilot deployment on vehicles

### Long-term (3-5 years)
1. ğŸ† Regulatory certification for AVs
2. ğŸ“¡ V2X infrastructure integration
3. ğŸ”„ Continual learning system
4. ğŸ”§ Custom edge AI hardware

---

## âœ… Project Completion Status

1. âœ… Set up environment and dependencies
2. âœ… Collect and annotate Bangladeshi traffic sign dataset
3. âœ… Preprocess dataset
4. âœ… Train YOLOv11 model
5. âœ… Train SSD model
6. âœ… Evaluate and compare models
7. âœ… Deploy best performing model

---

## ğŸ¤ Contributing

We welcome contributions! Areas for help:
- ğŸ› Bug fixes
- ğŸ“Š New datasets (other regions)
- ğŸ¨ UI/UX improvements
- ğŸ“š Documentation

---

## ğŸ“§ Contact

- **Email**: research@bdtrafficsigns.org
- **Issues**: [GitHub Issues](https://github.com/your-username/bd-traffic-signs/issues)

---

## ğŸ™ Acknowledgments

- **BRTA** for domain expertise
- **Ultralytics** for YOLOv11 framework
- **Annotators** for 200+ hours of work

---

## ğŸ“œ License

MIT License

**Dataset**: CC BY 4.0

---

<div align="center">

**Made with â¤ï¸ for the Bangladeshi AI Community**

[â¬† Back to Top](#-yolov11-vs-ssd-for-bangladeshi-traffic-sign-detection)

</div>
